input {
  file {
    path => "/usr/share/logstash/ingest_data/mock_data.csv"  # Chemin vers le fichier CSV
    start_position => "beginning"
    sincedb_path => "/dev/null"  # Réinitialise la lecture à chaque redémarrage
    mode => "tail"

  }
}

filter {
  csv {
    separator => ","
    columns => ["insertdate", "source", "tablename", "nb_lines_collected", "nb_lines_filtered", "nb_lines_enriched", "nb_lines_ingested_hive", "nb_events_hive"]
  }
  mutate {
    convert => {
      "nb_lines_collected" => "integer"
      "nb_lines_filtered" => "integer"
      "nb_lines_enriched" => "integer"
      "nb_lines_ingested_hive" => "integer"
      "nb_events_hive" => "integer"
    }
  }
  date {
    match => ["insertdate", "ISO8601"]
  }
}

output {
  elasticsearch {
    hosts => "https://es01:9200"
    index => "data_realtime_ingestion"
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl_enabled => true
    ssl_verification_mode => "none"
  }
   stdout { codec => rubydebug }
}
